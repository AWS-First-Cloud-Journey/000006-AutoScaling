[
{
	"uri": "//localhost:1313/4-setup-load-balancer/4.1-create-target-group/",
	"title": "Create Target Group",
	"tags": [],
	"description": "",
	"content": "Creating an Application Load Balancer Target Group ‚ÑπÔ∏è Information: Target groups route requests to individual registered targets such as EC2 instances. When creating a load balancer, you define at least one target group, then register targets to that group.\nNavigate to the Target Group creation interface:\nIn the EC2 management console, locate the Load Balancing section in the left navigation pane Select Target Groups Click Create target group Configuring Target Group Details In the Specify group details section, configure the following settings:\nBasic configuration: Target type: Instances Target group name: FCJ-Management-TG Network settings: Protocol: HTTP Port: 5000 IP address type: IPv4 VPC: AutoScaling-Lab Protocol version: HTTP1 Click Next to proceed to target registration Registering Targets In the Register targets section:\nSelect your instance from the Available instances list Verify port 5000 is specified for the selected instance Click Include as pending below Review the pending targets in the list Click Create target group to complete the process Verifying Target Group Creation After successful creation, you can view and manage your new target group:\nSelect the newly created FCJ-Management-TG from the target groups list Review the target group details, health status, and registered targets üí° Pro Tip: Target groups support health checks to ensure traffic is only routed to healthy instances. You can customize health check settings including path, port, threshold counts, and timeout values to match your application\u0026rsquo;s specific requirements.\nüîí Security Note: When configuring target groups, consider using HTTPS protocol with proper certificate management for production workloads to ensure encrypted communication between clients and your load balancer.\n"
},
{
	"uri": "//localhost:1313/",
	"title": "Deploying FCJ Management with Auto Scaling Group",
	"tags": [],
	"description": "",
	"content": "Deploying FCJ Management Application with Auto Scaling Group Overview ‚ÑπÔ∏è Information: In this workshop, you will deploy an application with Amazon EC2 Auto Scaling to ensure dynamic scalability based on fluctuating workloads. Additionally, you will implement Elastic Load Balancing to distribute traffic and efficiently manage user requests to your application tier.\nMake sure to review the Deploying FCJ Management Application on a Windows/Amazon Linux Virtual Machine documentation to understand the base deployment process. We will leverage this foundation to implement a highly available, fault-tolerant architecture using AWS\u0026rsquo;s elastic scaling capabilities.\nüí° Pro Tip: Auto Scaling Groups combined with Application Load Balancers create a resilient architecture that can automatically adjust capacity to maintain performance during traffic spikes while optimizing costs during periods of low demand.\nüîí Security Note: This architecture follows AWS Well-Architected Framework principles, ensuring your application deployment meets industry best practices for reliability, performance efficiency, and cost optimization.\nContents Introduction Preparation Create Launch Template Setup Load Balancer Test Create Auto Scaling Group Test Solutions Clean up Resources "
},
{
	"uri": "//localhost:1313/1-introduction/",
	"title": "Introduction",
	"tags": [],
	"description": "",
	"content": "Introduction ‚ÑπÔ∏è Information: In this workshop, we will deploy an application using Amazon EC2 Auto Scaling to ensure dynamic scalability based on user demand. Additionally, we will implement Elastic Load Balancing to distribute traffic and efficiently manage user requests to our application tier.\nBefore proceeding, please review the document [Deploying FCJ Management Application on a Windows/Amazon Linux Virtual Machine] to understand the base deployment process. We will use the virtual machine with FCJ Management already deployed as the foundation for our Auto Scaling Group configuration.\nAmazon EC2 Auto Scaling ‚ÑπÔ∏è Information: When applications go into production, user traffic naturally fluctuates over time. To maintain optimal performance and cost efficiency, we need to adjust (scale) the number of instances accordingly. Amazon EC2 Auto Scaling provides an automated solution that makes this scaling process flexible and hands-free.\nAmazon EC2 Auto Scaling automatically adjusts the number of EC2 instances based on application demand. It can scale out (add instances) when traffic increases and scale in (remove instances) when traffic decreases, optimizing resource utilization and reducing costs. It also enhances high availability by distributing instances across multiple Availability Zones, ensuring continuous operation even if part of the infrastructure experiences issues.\nScaling Strategies In this workshop, we will explore the following scaling strategies:\nManual Scaling: Manually adjusting the number of EC2 instances in the Auto Scaling group based on anticipated demand. This method requires human intervention and does not automatically respond to metrics.\nDynamic Scaling: Automatically adjusting capacity based on real-time metrics such as CPU utilization, network traffic, or custom CloudWatch metrics. Dynamic scaling includes three primary approaches:\nTarget Tracking Scaling: Maintains a specific metric value (e.g., 50% CPU utilization) Step Scaling: Responds to metric thresholds with proportional capacity adjustments Simple Scaling: Adjusts capacity based on a single metric threshold Scheduled Scaling: Configuring specific times to automatically scale instances up or down, such as increasing capacity during business hours and decreasing it during off-hours. This works well for predictable traffic patterns.\nPredictive Scaling: Forecasts future capacity needs by analyzing historical load patterns. This proactive approach allows Amazon EC2 Auto Scaling to scale out in advance of anticipated traffic increases, ensuring optimal performance during peak periods.\nLaunch Templates ‚ÑπÔ∏è Information: A Launch Template is a configuration that contains all the necessary parameters to launch EC2 instances. It stores specifications such as instance type, Amazon Machine Image (AMI), key pair, network settings, security groups, and other EC2 configuration details. Launch Templates simplify the instance creation process and enable Auto Scaling groups to consistently deploy properly configured instances.\nüí° Pro Tip: Launch Templates support versioning, allowing you to iterate on your configuration while maintaining the ability to roll back if needed.\nElastic Load Balancing ‚ÑπÔ∏è Information: Elastic Load Balancing automatically distributes incoming application traffic across multiple targets, such as EC2 instances, containers, and IP addresses. It helps ensure high availability and fault tolerance by preventing any single resource from becoming overwhelmed with traffic. If one server experiences issues, traffic is automatically redirected to healthy servers, maintaining a seamless user experience.\nüîí Security Note: Elastic Load Balancing integrates with AWS Certificate Manager to provide SSL/TLS termination, enhancing security for your applications without adding computational overhead to your instances.\nTarget Groups ‚ÑπÔ∏è Information: A Target Group is a component of Elastic Load Balancing that identifies and manages the destinations (targets) to which the load balancer routes traffic. Target Groups allow you to register multiple EC2 instances, configure health checks, and set routing rules. They serve as the bridge between your load balancer and the application instances, enabling intelligent traffic distribution based on health and availability.\n"
},
{
	"uri": "//localhost:1313/2-preparation/2.1-setup-network/",
	"title": "Setup Network Infrastructure",
	"tags": [],
	"description": "",
	"content": "Creating Your VPC Environment ‚ÑπÔ∏è Information: In this section, we\u0026rsquo;ll create a Virtual Private Cloud (VPC) with public and private subnets across multiple Availability Zones to ensure high availability for our Auto Scaling architecture.\nNavigate to the AWS Management Console\nIn the search bar, find and select VPC In the VPC Console:\nClick Create VPC In the Create VPC interface:\nSelect VPC and more for the comprehensive setup wizard For VPC name, enter AutoScaling-Lab For IPv4 CIDR block, enter 10.0.0.0/16 Configure the VPC architecture:\nNumber of Availability Zones: 3 (for maximum resilience) Number of public subnets: 3 (one per AZ) Number of private subnets: 3 (one per AZ) NAT gateways: None (we\u0026rsquo;ll keep costs minimal for this lab) Finalize the VPC creation:\nVPC endpoints: None Click Create VPC Configuring Public Subnet Auto-Assignment ‚ÑπÔ∏è Information: For EC2 instances in public subnets to receive public IP addresses automatically, we need to enable auto-assign public IPv4 addresses.\nTo enable auto-assign public IP:\nSelect Subnets in the left navigation Select a public subnet Click Edit subnet settings In the subnet settings:\nCheck Enable auto-assign public IPv4 address Click Save Verify the configuration was successful:\nüí° Pro Tip: Repeat this process for all public subnets to ensure any EC2 instance launched in these subnets automatically receives a public IP address.\nCreating Application Security Group ‚ÑπÔ∏è Information: Security Groups act as virtual firewalls for your instances to control inbound and outbound traffic.\nTo create a security group for your application:\nIn the VPC console, select Security groups Click Create security group Configure the basic security group details:\nSecurity group name: FCJ-Management-SG Description: Security Group for FCJ Management VPC: Select the AutoScaling-Lab VPC you created Configure the inbound rules:\nAdd rule for SSH (port 22) with Source: My IP for secure administrative access Add rule for HTTP (port 80) with Source: Anywhere-IPv4 for web traffic Add rule for Custom TCP (port 5000) with Source: Anywhere-IPv4 for the FCJ Management application Add rule for HTTPS (port 443) with Source: Anywhere-IPv4 for secure web traffic üîí Security Note: In a production environment, consider restricting access to specific IP ranges rather than using \u0026ldquo;Anywhere\u0026rdquo; for enhanced security.\nReview the outbound rules (default allows all outbound traffic) and click Create security group\nCreating Database Security Group ‚ÑπÔ∏è Information: For database instances, we\u0026rsquo;ll create a separate security group with more restrictive access controls to enhance security.\nConfigure the database security group:\nSecurity Group name: FCJ-Management-DB-SG Description: Security Group for DB instance VPC: Select your AutoScaling-Lab VPC Configure the inbound rules:\nAdd rule for MYSQL/Aurora (port 3306) Set the source to the application security group FCJ-Management-SG üîí Security Note: By referencing the application security group as the source, you ensure that only EC2 instances with that security group can access the database, following the principle of least privilege.\nReview the outbound rules and click Create Security Group\nüí° Pro Tip: This network architecture with separate security groups for application and database tiers follows AWS Well-Architected best practices for security and isolation.\n"
},
{
	"uri": "//localhost:1313/7-test-solutions/7.1-test-manual-scaling-solution/",
	"title": "Test manual scaling solution",
	"tags": [],
	"description": "",
	"content": "Overview ‚ÑπÔ∏è Information: Manual Scaling is performed by explicitly adjusting the Desired capacity parameter of your Auto Scaling Group. After modifying this value and confirming the update, the ASG will automatically launch or terminate EC2 instances to match your specified capacity.\nTest Environment Setup Once your Auto Scaling Group is created, the service automatically launches an EC2 instance according to your configuration. To verify this deployment:\nNavigate to the EC2 Console Select Load Balancer Choose the Resource map - new tab ‚ÑπÔ∏è Information: You should observe the Target Group linked to two targets - your original EC2 instance and the new instance created by the Auto Scaling Group.\nConfiguring the Load Test Now we\u0026rsquo;ll configure the load testing application downloaded earlier:\nOpen the application and navigate to the Test Type tab Configure the following settings: Test Type: CLICKS Run until: 100000 Number Of Users: 1000 Click Delay: 1 second In the URLs tab, enter: Name: Manual Scaling Test (this can be customized as needed) URL: Enter your Load Balancer\u0026rsquo;s DNS name Click Start Test on the toolbar to begin the load test Monitoring Instance Performance While the test is running, return to the AWS Management Console:\nIn the EC2 Console, select both EC2 instances in the target group Click on the Monitoring tab to observe performance metrics üí° Pro Tip: Focus on these five key metrics to understand your application\u0026rsquo;s performance under load:\nCPU Utilization (%): Shows processor usage (currently below 8% for each instance) Network in (bytes): Measures incoming traffic (under 2.9 million MB per instance) Network out (bytes): Measures outgoing traffic (under 17.3 million MB per instance) Network packets in (count): Shows incoming packet count (under 6.85 thousand packets per instance) Network packets out (count): Shows outgoing packet count (under 7.36 thousand packets per instance) ‚ÑπÔ∏è Information: The charts display one line per selected instance. Selecting multiple instances allows you to compare their performance simultaneously, helping you understand how the Load Balancer distributes traffic.\nManually Scaling Down the ASG To simulate cost optimization during off-peak hours:\nNavigate to your Auto Scaling Group details page Note the current setting: Desired capacity = 1 Click Edit to modify the capacity In the Group size dialog, set both Desired capacity and Min desired capacity to 0 Click Update to apply the changes Navigate to the Activity tab to monitor the scaling action ‚ö†Ô∏è Warning: While the instance is being terminated, you should pause your load testing application to avoid potential errors.\n‚ÑπÔ∏è Information: The ASG will automatically terminate an instance based on your updated configuration. After a few minutes, returning to the Load Balancer\u0026rsquo;s Resource map will show only one remaining target.\nüí° Pro Tip: Remember to restart your load testing program after the scaling operation completes to continue your testing.\nObserving Notification and Performance Impact After scaling down, you\u0026rsquo;ll receive an email notification from Amazon SNS:\nWith reduced capacity, you may notice performance degradation when accessing your application through the Load Balancer\u0026rsquo;s DNS:\nReturn to the EC2 Console to observe the impact on your remaining instance:\n‚ÑπÔ∏è Information: The monitoring data clearly shows that the remaining instance is now handling approximately double the network traffic, with CPU utilization nearly quadrupled compared to the previous balanced state.\nConclusion ‚ö†Ô∏è Warning: This demonstration uses simple GET requests, but real-world applications typically involve more complex operations that consume significantly more CPU resources and may experience more dramatic performance impacts during scaling events.\nüîí Security Note: While manual scaling provides direct control over your infrastructure costs, it requires human intervention and monitoring, which can lead to delayed responses during unexpected traffic spikes. Consider implementing automated scaling policies for production workloads to maintain both performance and security.\n"
},
{
	"uri": "//localhost:1313/4-setup-load-balancer/4.2-create-load-balancer/",
	"title": "Create Load Balancer",
	"tags": [],
	"description": "",
	"content": "Creating an Application Load Balancer ‚ÑπÔ∏è Information: Application Load Balancers operate at the application layer (Layer 7) and are ideal for HTTP/HTTPS traffic routing. They provide advanced request routing capabilities, support for containerized applications, and integration with AWS services.\nNavigate to the Load Balancer creation interface:\nIn the EC2 management console: Select Load Balancers from the left navigation pane Click the Create Load Balancer button In the \u0026ldquo;Compare and select load balancer type\u0026rdquo; panel: Locate the Application Load Balancer section Click Create Configuring Load Balancer Settings In the \u0026ldquo;Create Application Load Balancer\u0026rdquo; configuration panel:\nBasic configuration: Load balancer name: FCJ-Management-LB Scheme: Internet-facing IP address type: IPv4 Network mapping: VPC: AutoScaling-Lab Availability Zones: Select all three public subnets in ap-southeast-1a, ap-southeast-1b, and ap-southeast-1c ‚ö†Ô∏è Warning: Ensure you select only public subnets for internet-facing load balancers. Private subnets cannot receive traffic from the internet.\nSecurity and routing configuration: Security groups: FCJ-Management-SG Listeners and routing: Set default action to forward to FCJ-Management-TG Review the configuration summary: Verify all settings are correct Click Create load balancer Verifying Load Balancer Deployment After successful creation:\nSelect FCJ-Management-LB from the load balancers list Review the load balancer details, including DNS name, state, and listeners Explore the load balancer\u0026rsquo;s connections: Select Resource map - new to visualize the load balancer architecture Verify connections to target groups and registered targets üí° Pro Tip: Application Load Balancers support content-based routing, allowing you to route requests to different target groups based on URL paths, host headers, or query parameters. This enables microservices architectures where different services handle specific request patterns.\nüîí Security Note: For production workloads, consider implementing HTTPS listeners with certificates from AWS Certificate Manager (ACM) to ensure encrypted communication between clients and your load balancer.\n"
},
{
	"uri": "//localhost:1313/2-preparation/2.2-launch-ec2-instance/",
	"title": "Launch EC2 Instance",
	"tags": [],
	"description": "",
	"content": "Launching an EC2 Instance ‚ÑπÔ∏è Information: In this section, we\u0026rsquo;ll launch an Amazon EC2 instance that will serve as the foundation for our Auto Scaling configuration. This instance will be used to create an Amazon Machine Image (AMI) for our Launch Template.\nAccess the AWS Management Console:\nIn the search bar, find and select EC2 In the EC2 console:\nClick Launch instances Configure Basic Instance Details For the instance name:\nEnter FCJ-Management Select Amazon Machine Image (AMI) For the operating system:\nSelect Quick Start Choose Amazon Linux Select Amazon Linux 2023 AMI Configure Instance Type and Key Pair For compute resources:\nSelect t2.micro instance type Click Create new key pair üîí Security Note: The key pair is essential for secure SSH access to your instance. Store the private key securely and never share it.\nConfigure the key pair:\nName: fcj-key Key pair type: RSA Private key format: .pem Click Create key pair Configure Network Settings For network configuration:\nClick the Edit button VPC: Select the VPC you created in the previous step Subnet: Choose a Public subnet Ensure Auto-assign public IP is enabled üí° Pro Tip: Placing this instance in a public subnet allows direct internet access, which is necessary for initial setup and configuration.\nConfigure Security Group For access control:\nSelect Select existing security group Choose FCJ-Management-SG Click Launch instance Review and Launch Verify your instance is launching:\n‚ö†Ô∏è Warning: After launching, your instance may take a few minutes to initialize. Wait until the instance state shows as \u0026ldquo;running\u0026rdquo; and status checks have passed before proceeding to the next step.\n"
},
{
	"uri": "//localhost:1313/2-preparation/",
	"title": "Preparation",
	"tags": [],
	"description": "",
	"content": "Overview ‚ÑπÔ∏è Information: In this section, we will prepare the necessary AWS services to deploy the FCJ Management application using Amazon EC2 Auto Scaling and Elastic Load Balancing. This preparation ensures our application will be highly available, fault-tolerant, and capable of handling varying workloads efficiently.\nThe architecture we\u0026rsquo;ll implement follows AWS best practices for scalable web applications:\nüí° Pro Tip: This multi-tier architecture separates the web tier from the database tier, allowing each component to scale independently based on its specific resource requirements.\nWorkshop Modules Setup Network Infrastructure Launch EC2 Instance Deploy Database with Amazon RDS Configure Database Data Deploy Web Server Prepare Metrics for Predictive Scaling üîí Security Note: Throughout this workshop, we\u0026rsquo;ll implement security best practices including proper network segmentation, secure access controls, and encrypted data transmission to protect our application and its data.\n"
},
{
	"uri": "//localhost:1313/7-test-solutions/7.2-test-scheduled-scaling-solution/",
	"title": "Test scheduled scaling solution",
	"tags": [],
	"description": "",
	"content": "Overview ‚ÑπÔ∏è Information: Scheduled Scaling enables you to configure your Auto Scaling Group to automatically adjust capacity based on predictable load changes. This approach is ideal for workloads with consistent patterns that occur at specific times daily, weekly, or seasonally.\nTest Environment Setup Since we\u0026rsquo;ve already configured our load testing environment in the previous section, we\u0026rsquo;ll continue using those settings for consistency in our comparison of scaling methods.\nConfiguring Scheduled Scaling To implement scheduled scaling:\nNavigate to your Auto Scaling Group details page Select the Automatic scaling tab Scroll to the Scheduled actions section at the bottom of the page Click Create scheduled action Configure the scheduled action with these parameters: Name: Rush hour Desired capacity: 1 Min: 1 (can be set to 0 depending on your requirements) Max: 3 Recurrence: Once (or select another pattern as needed) Time zone: Asia/Ho_Chi_Minh (select your appropriate time zone) Specific start time: Set to the nearest time from your current configuration Click Create to implement the scheduled action ‚ö†Ô∏è Warning: The Desired capacity, Min, and Max parameters will override the corresponding ASG settings during the scheduled period. When implementing multiple scaling types in production, carefully consider how these values interact with other scaling policies.\nAfter successful creation, you\u0026rsquo;ll see your scheduled action in the list:\nTesting the Scheduled Scaling For effective testing:\nStart your load testing program approximately 5 minutes before the scheduled scaling action is set to trigger When the scheduled time arrives, monitor the Activity tab of your ASG You should observe the Executing scheduled action Rush hour event triggering at the configured time, followed by the launch of a new instance Analyzing the Results To evaluate the effectiveness of scheduled scaling:\nReturn to the EC2 Console and examine the instance metrics (note that metrics update every 15 minutes) Focus on the CPU Utilization chart to observe the impact of your test üí° Pro Tip: In this example, you can see a CPU utilization spike between 14:30 and 14:40, which corresponds to when we initiated the load test. After the new instance was added by the scheduled action, the load was distributed, resulting in the subsequent decline.\nFor more detailed analysis, select the newly launched instance and adjust the chart view: Select 1h timeframe Select 1 second granularity This granular view clearly shows how the scheduled scaling action affected system performance.\nReal-World Applications ‚ÑπÔ∏è Information: Scheduled Scaling is particularly valuable for applications with predictable usage patterns:\nFinancial trading platforms with market opening/closing traffic spikes E-commerce sites during daily peak shopping hours Enterprise applications with business-hour usage patterns Batch processing jobs that run at specific times üîí Security Note: While scheduled scaling helps optimize resource utilization, it\u0026rsquo;s important to maintain minimum capacity levels that can handle unexpected traffic surges or potential DDoS attacks outside of scheduled scaling periods.\nConclusion Scheduled Scaling provides a proactive approach to capacity management for workloads with predictable patterns. However, for maximum resilience and cost efficiency, AWS recommends combining scheduled scaling with other scaling types:\nUse scheduled scaling for predictable, time-based patterns Implement dynamic scaling to handle unexpected traffic variations Consider predictive scaling for workloads with complex but recurring patterns This multi-layered approach ensures your application remains responsive while optimizing resource utilization and cost.\n"
},
{
	"uri": "//localhost:1313/3-create-launch-template/",
	"title": "Create Launch Template",
	"tags": [],
	"description": "",
	"content": "Overview ‚ÑπÔ∏è Information: In this section, we\u0026rsquo;ll create a Launch Template using an Amazon Machine Image (AMI) from our existing EC2 instance. This approach ensures consistent deployment of our application across multiple instances.\nUnderstanding AMIs and Launch Templates ‚ÑπÔ∏è Information: Amazon Machine Images (AMIs) capture the complete state of an EC2 instance, including the operating system, applications, and configurations. Launch Templates define the complete instance configuration, including AMI, instance type, networking, and security settings, enabling consistent and repeatable deployments.\nCreating an Amazon Machine Image (AMI) To create an AMI from your existing EC2 instance:\nNavigate to the EC2 console In the left navigation pane, select Instances Select the FCJ-Management instance Click Actions ‚Üí Image and templates ‚Üí Create image Configure the AMI with the following settings:\nImage name: FCJ-Management-AMI Image description: AMI for FCJ-Management Click Create Image Verify the AMI creation:\nIn the left navigation pane, select AMIs Locate and select FCJ-Management-AMI ‚ö†Ô∏è Warning: The AMI creation process takes approximately 3 minutes to complete. Wait until the Status changes to Available before proceeding.\nCreating a Launch Template Once your AMI is available, create a Launch Template:\nIn the EC2 console, select Launch Templates from the left navigation pane Click Create launch template Configure the basic template information:\nLaunch template name: FCJ-Management-template Template version description: Template for FCJ Management Configure the AMI and instance specifications:\nUnder Application and OS Image: Select My AMIs Choose Owned by me Select the FCJ-Management-AMI you created earlier Configure instance details: Instance type: t2.micro Key pair: fcj-key Configure network settings: Subnet: AutoScaling-Lab-public-ap-southeast-1a Security group: Select Select existing security group and choose FCJ-Management-SG Click Create launch template Verifying the Launch Template After creation, verify your Launch Template:\nSelect FCJ-Management-template from the Launch Templates list Review the template configuration details to ensure all settings are correct üí° Pro Tip: Launch Templates support versioning, allowing you to iterate on your configuration while maintaining the ability to roll back to previous versions if needed.\nüîí Security Note: When creating Launch Templates, always follow the principle of least privilege by assigning only the necessary permissions to your instances through security groups and IAM roles.\n"
},
{
	"uri": "//localhost:1313/2-preparation/2.3-launch-db-instance/",
	"title": "Launch a Database Instance with RDS",
	"tags": [],
	"description": "",
	"content": "Creating a DB Subnet Group ‚ÑπÔ∏è Information: A DB subnet group is a collection of subnets that you designate for your RDS database instances within a VPC. This configuration ensures high availability by allowing Amazon RDS to deploy instances across multiple Availability Zones.\nAccess the AWS Management Console:\nIn the search bar, find and select Aurora and RDS In the Aurora and RDS console:\nSelect Subnet groups from the left navigation panel Click Create DB subnet group Configure the DB subnet group details:\nFor Name, enter FCJ-Management-Subnet-Group For Description, enter Subnet Group for FCJ Management Select the VPC you created earlier (AutoScaling-Lab) Configure the subnet selection:\nSelect multiple Availability Zones for redundancy Choose the private subnets for enhanced security üîí Security Note: Always place your database instances in private subnets to prevent direct internet access, reducing your attack surface.\nComplete the creation:\nClick Create Verify the DB subnet group has been created successfully with multiple AZs:\nLaunching an Amazon RDS Database Instance ‚ÑπÔ∏è Information: Amazon RDS makes it easy to set up, operate, and scale a relational database in the cloud. It provides cost-efficient and resizable capacity while automating time-consuming administration tasks.\nNavigate to the RDS console:\nSelect Databases from the left navigation panel Click Create database Select the database creation method:\nChoose Standard create for full configuration options Select the database engine:\nChoose MySQL Configure the deployment template:\nSelect Production template Choose Multi-AZ DB instance for high availability üí° Pro Tip: Multi-AZ deployments enhance availability by automatically provisioning and maintaining a synchronous standby replica in a different Availability Zone.\nConfigure instance details:\nFor DB instance identifier, enter fcj-management-db-instance For Master username, enter admin Select Self managed for credential management Set the database password:\nFor Master password, enter a strong password (for this lab: 123Vodanhphai) Confirm the password üîí Security Note: In production environments, always use complex passwords and consider using AWS Secrets Manager to automatically rotate credentials.\nConfigure instance specifications:\nSelect db.m5d.large for the instance class Choose General Purpose SSD (gp3) for storage type Set Allocated storage to 20 GiB Configure connectivity settings:\nSelect Don\u0026rsquo;t connect to an EC2 compute resource For VPC, select your created VPC (AutoScaling-Lab) For Subnet group, choose the subnet group you created earlier Configure security settings:\nFor VPC security group, select Choose existing For Security Group, select FCJ-Management-DB-SG üîí Security Note: Using dedicated security groups for your database tier helps maintain proper network segmentation and access control.\nConfigure initial database settings:\nSet the initial database name to awsfcjuer Leave other settings at their default values Complete the database creation:\nClick Create database Verify successful database creation:\nNote the database endpoint and port for future reference:\nüí° Pro Tip: You\u0026rsquo;ll need this endpoint information when configuring your application to connect to the database.\n"
},
{
	"uri": "//localhost:1313/7-test-solutions/7.3-test-dynamic-scaling-solution/",
	"title": "Test dynamic scaling solution",
	"tags": [],
	"description": "",
	"content": "Overview ‚ÑπÔ∏è Information: Dynamic scaling automatically adjusts your application\u0026rsquo;s capacity based on real-time metrics collected by Amazon CloudWatch. When properly configured, your Auto Scaling Group (ASG) will launch or terminate instances in response to changing workload demands, ensuring optimal performance and cost efficiency.\nUnderstanding Dynamic Scaling Metrics Dynamic scaling can be triggered by various metrics, including:\nCPU utilization percentage Network traffic volume Application Load Balancer request count per target Custom metrics specific to your application üí° Pro Tip: The choice of scaling metric should align with your application\u0026rsquo;s performance bottlenecks. For web applications, request count per target often provides the most responsive scaling behavior.\nConfiguring Dynamic Scaling Before implementing dynamic scaling, we\u0026rsquo;ll first ensure our environment is properly prepared:\nManually scale in by terminating one instance to establish a baseline Verify the termination in the Activity tab of your ASG Now, let\u0026rsquo;s configure dynamic scaling:\nNavigate to the Automatic scaling tab of your ASG Click Create dynamic scaling policy Configure the policy with these parameters: Policy type: Target tracking scaling Scaling policy name: Request Over 500 per target Metric type: Application Load Balancer request count per target Target group: FCJ-Management-TG Target value: 500 (requests) Instance warmup: 60 seconds Click Create to implement the policy ‚ÑπÔ∏è Information: The Instance warmup parameter defines how long a newly launched instance should be excluded from aggregated metrics. This allows the instance to initialize fully before it\u0026rsquo;s considered in scaling decisions. For production workloads, consider setting this value higher (120-300 seconds) depending on your application\u0026rsquo;s initialization requirements.\nAfter successful creation, you\u0026rsquo;ll see your dynamic scaling policy in the list:\nTesting Dynamic Scaling To evaluate the effectiveness of dynamic scaling:\nStart your load testing program with the same configuration used in previous tests Monitor the EC2 Console to observe the request metrics for your instances ‚ö†Ô∏è Warning: CloudWatch metrics may take several minutes to update. Be patient and observe the trend lines as they begin to stabilize or increase.\nReturn to the Activity tab of your ASG to monitor scaling actions ‚ÑπÔ∏è Information: In this example, the ASG has determined that three instances are needed to handle the current request volume, scaling up to the maximum desired capacity we configured.\nIn the EC2 Console, select all instances to compare their performance metrics üí° Pro Tip: Notice how the green line (representing your original instance) gradually decreases as new instances (represented by other colors) begin handling portions of the traffic. This demonstrates the load balancer distributing requests across all available instances.\nStop the load testing program to observe scale-in behavior Monitor the ASG Activity tab as unnecessary instances are terminated ‚ö†Ô∏è Warning: Scale-in actions typically have a cooldown period to prevent rapid scaling oscillations. This means termination of excess instances may take several minutes after load decreases.\nKey Insights and Best Practices ‚ÑπÔ∏è Information: Dynamic scaling responds to real-time metrics, making it ideal for workloads with unpredictable traffic patterns. However, there are important considerations:\nMetric Selection: Choose metrics that directly correlate with user experience and system performance Target Values: Set appropriate target values based on performance testing and application requirements Warmup Periods: Configure realistic warmup times that allow your application to fully initialize Scale-In Protection: Consider enabling instance scale-in protection for critical workloads Monitoring: Regularly review scaling activities to optimize your configuration üîí Security Note: When implementing dynamic scaling, ensure your security groups, IAM roles, and network configurations are properly set to maintain security posture during scaling events.\nConclusion Dynamic scaling provides an effective way to automatically adjust capacity based on real-time demand. While it offers significant advantages over manual or scheduled scaling for unpredictable workloads, it does have inherent limitations:\nThere\u0026rsquo;s an unavoidable delay between metric collection, evaluation, and scaling action Rapid traffic spikes may temporarily impact performance before scaling completes Determining optimal target values requires testing and refinement For workloads with more predictable patterns or those requiring faster response to changing conditions, consider implementing predictive scaling, which we\u0026rsquo;ll explore in the next section.\n"
},
{
	"uri": "//localhost:1313/7-test-solutions/7.4-test-predictive-scaling-solution/",
	"title": "Read metrics of predictive scaling solution",
	"tags": [],
	"description": "",
	"content": "Predictive Scaling From the traffic and workloads that the system receives and sends each day, ASG can \u0026ldquo;predict\u0026rdquo; the future traffic and workloads for the upcoming days. This helps ASG respond better by launching or terminating instances accordingly. Typically, Predictive Scaling is used in combination with other types of scaling.\nConfiguration As in the previous section, I will manually scale in with ASG and wait for ASG to terminate all the instances created by this service.\nNext, delete the automatic scaling policy to avoid affecting this test.\nThen, go to the Automatic Scaling tab, scroll down to Predictive scaling policies, and click Create predictive policy to create a new one.\nIn this form, we will configure as follows:\nPolicy details Name: PredictCPUUtilizationAt15Percent (you can choose any name) Turn on scaling: enable Scale based on forecast. With the predictive scaling policy, essentially, it only makes predictions, but we can also use it to launch instances. Next, in the Metric and target utilization section:\nMetrics: select Custom metric pair. Load metric: select Custom CloudWatch metric. Scaling metric: select Custom CloudWatch metric. You will add custom metric JSON as follows:\nFor Load metric { \u0026#34;CustomizedLoadMetricSpecification\u0026#34;: { \u0026#34;MetricDataQueries\u0026#34;: [ { \u0026#34;Label\u0026#34;: \u0026#34;Total CPU Utilization in ASG\u0026#34;, \u0026#34;Id\u0026#34;: \u0026#34;cpu_sum\u0026#34;, \u0026#34;MetricStat\u0026#34;: { \u0026#34;Metric\u0026#34;: { \u0026#34;MetricName\u0026#34;: \u0026#34;WSCustomCPUUTILIZATION\u0026#34;, \u0026#34;Namespace\u0026#34;: \u0026#34;FCJ Management Custom Metrics\u0026#34;, \u0026#34;Dimensions\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;AutoScalingGroupName\u0026#34;, \u0026#34;Value\u0026#34;: \u0026#34;FCJ-Management-ASG\u0026#34; } ] }, \u0026#34;Stat\u0026#34;: \u0026#34;Sum\u0026#34; }, \u0026#34;ReturnData\u0026#34;: true } ] } } For Scaling metric { \u0026#34;CustomizedScalingMetricSpecification\u0026#34;: { \u0026#34;MetricDataQueries\u0026#34;: [ { \u0026#34;Label\u0026#34;: \u0026#34;Average CPU Utilization in ASG\u0026#34;, \u0026#34;Id\u0026#34;: \u0026#34;cpu_avg\u0026#34;, \u0026#34;MetricStat\u0026#34;: { \u0026#34;Metric\u0026#34;: { \u0026#34;MetricName\u0026#34;: \u0026#34;WSCustomCPUUTILIZATION\u0026#34;, \u0026#34;Namespace\u0026#34;: \u0026#34;FCJ Management Custom Metrics\u0026#34;, \u0026#34;Dimensions\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;AutoScalingGroupName\u0026#34;, \u0026#34;Value\u0026#34;: \u0026#34;FCJ-Management-ASG\u0026#34; } ] }, \u0026#34;Stat\u0026#34;: \u0026#34;Average\u0026#34; }, \u0026#34;ReturnData\u0026#34;: true } ] } } Next, check Add custom capacity metric.\nSimilarly to the previous two steps, I will add custom metric JSON for Capacity metric.\n{ \u0026#34;CustomizedCapacityMetricSpecification\u0026#34;: { \u0026#34;MetricDataQueries\u0026#34;: [ { \u0026#34;Label\u0026#34;: \u0026#34;Number of instances in ASG\u0026#34;, \u0026#34;Id\u0026#34;: \u0026#34;capacity_avg\u0026#34;, \u0026#34;MetricStat\u0026#34;: { \u0026#34;Metric\u0026#34;: { \u0026#34;MetricName\u0026#34;: \u0026#34;WSCustomGroupInstances\u0026#34;, \u0026#34;Namespace\u0026#34;: \u0026#34;FCJ Management Custom Metrics\u0026#34;, \u0026#34;Dimensions\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;AutoScalingGroupName\u0026#34;, \u0026#34;Value\u0026#34;: \u0026#34;FCJ-Management-ASG\u0026#34; } ] }, \u0026#34;Stat\u0026#34;: \u0026#34;Average\u0026#34; }, \u0026#34;ReturnData\u0026#34;: true } ] } } If you configured 2.6 - Prepare metrics for predictive scaling earlier, after completing the setup, you will see two charts displayed.\nIn the Pre-launch instances section of Additional scaling settings - optional, set it to 1 minute. Click Create to create the policy.\nSimilar to Dynamic scaling, this Pre-launch instances setting will affect when the instances will be launched. For example, if ASG predicts a peak at 23:00, it will launch instances at 22:59, according to the configuration.\nCheck the results.\nReading Metrics from Sample Data In that policy, you will see two charts: Load and Capacity. These charts provide data on previous traffic and the number of instances used in previous days, allowing predictions for the upcoming days, represented by the purple line.\nThe chart is in UTC+0, and we are in UTC+7, so you\u0026rsquo;ll need to add 7 hours when reading these charts.\nFirst, focus on the chart on the left. At 09:00 UTC (which is 16:00 in Vietnam time), the total load was 773.542.\nTo understand what this number represents, look at the chart on the right.\nWe can see that at that time, 13 instances were predicted to be launched, and the load correlates with these instances.\nYou can check other times as well.\nIf you wait for the predicted time, go to the ASG\u0026rsquo;s Activity tab, and you\u0026rsquo;ll see that ASG launches a new instance at 15:59, one minute before 16:00, as predicted above.\nConclusion We can combine Predictive Scaling with Dynamic Scaling or other scaling types to increase ASG\u0026rsquo;s flexibility and the system\u0026rsquo;s reliability. For systems with consistent load over time, using predictive scaling is also a reasonable approach.\n"
},
{
	"uri": "//localhost:1313/4-setup-load-balancer/",
	"title": "Setting Up Load Balancer",
	"tags": [],
	"description": "",
	"content": "Introduction to Elastic Load Balancing ‚ÑπÔ∏è Information: Elastic Load Balancing (ELB) automatically distributes incoming application traffic across multiple targets‚Äîsuch as Amazon EC2 instances, containers, and IP addresses‚Äîin multiple Availability Zones. This improves your application\u0026rsquo;s fault tolerance while ensuring seamless user experiences even during peak loads.\nKey Benefits of Elastic Load Balancing High availability through intelligent traffic distribution across multiple Availability Zones Advanced security with integrated TLS termination, certificate management, and authentication Automatic scaling that adjusts capacity in response to fluctuating traffic patterns Seamless integration with AWS services including Amazon EC2 Auto Scaling, AWS Certificate Manager, and Amazon VPC üí° Pro Tip: Select the optimal load balancer for your workload requirements:\nApplication Load Balancer (ALB) for HTTP/HTTPS applications with advanced routing Network Load Balancer (NLB) for ultra-high performance TCP/UDP/TLS traffic Gateway Load Balancer (GWLB) for transparent network security appliance deployment Classic Load Balancer for legacy applications running in the EC2-Classic network üîí Security Note: Enhance your security posture by combining Elastic Load Balancing with AWS WAF for protection against common web vulnerabilities and AWS Shield for comprehensive DDoS mitigation. For regulated workloads, ELB supports compliance with PCI DSS, HIPAA, and SOC standards.\nImplementation Steps Create Target Group Create Load Balancer "
},
{
	"uri": "//localhost:1313/2-preparation/2.4-add-data-to-db/",
	"title": "Setup data for Database",
	"tags": [],
	"description": "",
	"content": "Retrieve the Public IP address of the EC2 instance.\nUse MobaXterm to connect to the instance via SSH on port 22:\nSelect Session Select SSH For Remote host, enter the Public IPv4 address retrieved from the instance For Specify username, nh·∫≠p ec2-user Verify port 22 Select Advanced SSH settings Select Use private key and select keypair of instance. Click OK The result after SSH.\nWe use Git to clone the source code. First, install Git using the following command:\nsudo yum install git Install MySQL command-line client\nsudo dnf install mariadb105 Check if the installation was successful.\nmysql --version Connect to the MySQL command-line client (unencrypted)\nFor the -h parameter, replace it with the DNS name (endpoint) of the DB instance. You can find the DNS name in the detail console of the RDS you created. For the -P parameter, replace it with the port for the DB instance (3306). For the -u parameter, replace it with the master user you set when creating the RDS. After running the command, enter the master user password that you set during the creation of the RDS. mysql -h fcj-management-db-instance.cdysiiecu90g.ap-southeast-1.rds.amzonaws.com -P 3306 -u admin -p Successfully connected to the DB instance. Proceed to check the databases within the instance using the command, which will display a list of all databases.\nSHOW DATABASES; Select the database to make changes by using the USE command; use the initial database that you created when setting up the RDS.\nUSE \u0026#34;name of database\u0026#34;; Create a table in the awsuser database using the CREATE TABLE command.\nCREATE TABLE `awsfcjuser`.`user` ( `id` INT NOT NULL AUTO_INCREMENT , `first_name` VARCHAR(45) NOT NULL , `last_name` VARCHAR(45) NOT NULL , `email` VARCHAR(45) NOT NULL , `phone` VARCHAR(45) NOT NULL , `comments` TEXT NOT NULL , `status` VARCHAR(10) NOT NULL DEFAULT \u0026#39;active\u0026#39; , PRIMARY KEY (`id`)) ENGINE = InnoDB; Insert information into the table using the INSERT INTO command\nINSERT INTO `user` (`id`, `first_name`, `last_name`, `email`, `phone`, `comments`, `status`) VALUES (NULL, \u0026#39;Amanda\u0026#39;, \u0026#39;Nunes\u0026#39;, \u0026#39;anunes@ufc.com\u0026#39;, \u0026#39;012345 678910\u0026#39;, \u0026#39;\u0026#39;, \u0026#39;active\u0026#39;), (NULL, \u0026#39;Alexander\u0026#39;, \u0026#39;Volkanovski\u0026#39;, \u0026#39;avolkanovski@ufc.com\u0026#39;, \u0026#39;012345 678910\u0026#39;, \u0026#39;\u0026#39;, \u0026#39;active\u0026#39;), (NULL, \u0026#39;Khabib\u0026#39;, \u0026#39;Nurmagomedov\u0026#39;, \u0026#39;knurmagomedov@ufc.com\u0026#39;, \u0026#39;012345 678910\u0026#39;, \u0026#39;\u0026#39;, \u0026#39;active\u0026#39;), (NULL, \u0026#39;Kamaru\u0026#39;, \u0026#39;Usman\u0026#39;, \u0026#39;kusman@ufc.com\u0026#39;, \u0026#39;012345 678910\u0026#39;, \u0026#39;\u0026#39;, \u0026#39;active\u0026#39;), (NULL, \u0026#39;Israel\u0026#39;, \u0026#39;Adesanya\u0026#39;, \u0026#39;iadesanya@ufc.com\u0026#39;, \u0026#39;012345 678910\u0026#39;, \u0026#39;\u0026#39;, \u0026#39;active\u0026#39;), (NULL, \u0026#39;Henry\u0026#39;, \u0026#39;Cejudo\u0026#39;, \u0026#39;hcejudo@ufc.com\u0026#39;, \u0026#39;012345 678910\u0026#39;, \u0026#39;\u0026#39;, \u0026#39;active\u0026#39;), (NULL, \u0026#39;Valentina\u0026#39;, \u0026#39;Shevchenko\u0026#39;, \u0026#39;vshevchenko@ufc.com\u0026#39;, \u0026#39;012345 678910\u0026#39;, \u0026#39;\u0026#39;, \u0026#39;active\u0026#39;), (NULL, \u0026#39;Tyron\u0026#39;, \u0026#39;Woodley\u0026#39;, \u0026#39;twoodley@ufc.com\u0026#39;, \u0026#39;012345 678910\u0026#39;, \u0026#39;\u0026#39;, \u0026#39;active\u0026#39;), (NULL, \u0026#39;Rose\u0026#39;, \u0026#39;Namajunas \u0026#39;, \u0026#39;rnamajunas@ufc.com\u0026#39;, \u0026#39;012345 678910\u0026#39;, \u0026#39;\u0026#39;, \u0026#39;active\u0026#39;), (NULL, \u0026#39;Tony\u0026#39;, \u0026#39;Ferguson \u0026#39;, \u0026#39;tferguson@ufc.com\u0026#39;, \u0026#39;012345 678910\u0026#39;, \u0026#39;\u0026#39;, \u0026#39;active\u0026#39;), (NULL, \u0026#39;Jorge\u0026#39;, \u0026#39;Masvidal \u0026#39;, \u0026#39;jmasvidal@ufc.com\u0026#39;, \u0026#39;012345 678910\u0026#39;, \u0026#39;\u0026#39;, \u0026#39;active\u0026#39;), (NULL, \u0026#39;Nate\u0026#39;, \u0026#39;Diaz \u0026#39;, \u0026#39;ndiaz@ufc.com\u0026#39;, \u0026#39;012345 678910\u0026#39;, \u0026#39;\u0026#39;, \u0026#39;active\u0026#39;), (NULL, \u0026#39;Conor\u0026#39;, \u0026#39;McGregor \u0026#39;, \u0026#39;cmcGregor@ufc.com\u0026#39;, \u0026#39;012345 678910\u0026#39;, \u0026#39;\u0026#39;, \u0026#39;active\u0026#39;), (NULL, \u0026#39;Cris\u0026#39;, \u0026#39;Cyborg \u0026#39;, \u0026#39;ccyborg@ufc.com\u0026#39;, \u0026#39;012345 678910\u0026#39;, \u0026#39;\u0026#39;, \u0026#39;active\u0026#39;), (NULL, \u0026#39;Tecia\u0026#39;, \u0026#39;Torres \u0026#39;, \u0026#39;ttorres@ufc.com\u0026#39;, \u0026#39;012345 678910\u0026#39;, \u0026#39;\u0026#39;, \u0026#39;active\u0026#39;), (NULL, \u0026#39;Ronda\u0026#39;, \u0026#39;Rousey \u0026#39;, \u0026#39;rrousey@ufc.com\u0026#39;, \u0026#39;012345 678910\u0026#39;, \u0026#39;\u0026#39;, \u0026#39;active\u0026#39;), (NULL, \u0026#39;Holly\u0026#39;, \u0026#39;Holm \u0026#39;, \u0026#39;hholm@ufc.com\u0026#39;, \u0026#39;012345 678910\u0026#39;, \u0026#39;\u0026#39;, \u0026#39;active\u0026#39;), (NULL, \u0026#39;Joanna\u0026#39;, \u0026#39;Jedrzejczyk \u0026#39;, \u0026#39;jjedrzejczyk@ufc.com\u0026#39;, \u0026#39;012345 678910\u0026#39;, \u0026#39;\u0026#39;, \u0026#39;active\u0026#39;); Use the SELECT command to display the table.\nSELECT * FROM user; Use exit to leave. If you are unable to disconnect from the DB instance, use the key combination Ctrl+C.\n"
},
{
	"uri": "//localhost:1313/2-preparation/2.5-deploy-web-server/",
	"title": "Deploy Web Server",
	"tags": [],
	"description": "",
	"content": "Install Node Version Manager (nvm) by entering the following command into the terminal:\ncurl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.40.0/install.sh | bash Run the following three lines of commands in your terminal exactly as they appear to immediately start using nvm without having to close and reopen the terminal:\nexport NVM_DIR=\u0026#34;$HOME/.nvm\u0026#34; [ -s \u0026#34;$NVM_DIR/nvm.sh\u0026#34; ] \u0026amp;\u0026amp; \\. \u0026#34;$NVM_DIR/nvm.sh\u0026#34; [ -s \u0026#34;$NVM_DIR/bash_completion\u0026#34; ] \u0026amp;\u0026amp; \\. \u0026#34;$NVM_DIR/bash_completion\u0026#34; To install Node.js using nvm, enter the following command in the terminal.\nnvm install 20 Clone the application repository by running the following command in your terminal:\ngit clone https://github.com/First-Cloud-Journey/000004-EC2.git Navigate to the directory for lab 000004-EC2\ncd 000004-EC2 NPM, short for Node Package Manager, is a vital tool for managing JavaScript libraries and dependencies in Node.js applications.When you run the command npm init, it initializes a new Node.js project and creates a package.json file. This file contains metadata about the project, such as its name, version, description, and a list of dependencies.\nnpm init You should press Enter continuously to create the default value\nInstall pm2 globally; PM2 is used to manage and monitor running Node.js applications. It allows applications to run in the background.\nnpm install -g pm2 Next, we redefine the script to run the application. We will use vim or nano to open the package.json file and in the scripts section under the key start, assign it the following value. This will allow our application to run in the background:\npm2 start app.js Enter the following command to access the content of the package.json file:\nnano package.json Edit the file content as below: Continue using vim or nano to access the .env file, then enter the following content to set up the connection to the database.\nDB_HOST=\u0026#39;fcj-management-db-instance.cdysiiecu90g.ap-southeast-1.rds.amzonaws.com\u0026#39; DB_NAME=\u0026#39;awsfcjuser\u0026#39; DB_USER=\u0026#39;admin\u0026#39; DB_PASS=\u0026#39;123Vodanhphai\u0026#39; Proceed to start the application.\nnpm start The command pm2 status in PM2 is used to display the current status of all applications being managed by PM2. When you run this command, you\u0026rsquo;ll receive an overview of each application, including details like their state (running, stopped, etc.), memory usage, CPU usage, and the number of restarts. This helps in monitoring the performance and health of your Node.js applications effectively.\nNext, we need to obtain the public DNS of the instance so that we can access the application from the browser.\nOur application is running stably\nNext, we use the command pm2 startup to configure PM2 to automatically restart applications when the server reboots. It will prompt you to set up a Startup Script. Please copy and paste that command and execute it.\nTo ensure that the running applications are saved and restarted when the server reboots, we need to run the command pm2 save. This command will save the current state of the processes to the startup list.\n"
},
{
	"uri": "//localhost:1313/5-test/",
	"title": "Test",
	"tags": [],
	"description": "",
	"content": "Overview ‚ÑπÔ∏è Information: In this section, we\u0026rsquo;ll verify that our application is properly deployed behind the Application Load Balancer and functioning as expected. This testing phase ensures our infrastructure is correctly configured before proceeding to auto scaling implementation.\nAccessing the Application To test the deployment:\nNavigate to the EC2 console and select Load Balancers Locate the FCJ-Management-LB and copy its DNS name Paste the DNS name into your browser\u0026rsquo;s address bar üí° Pro Tip: The DNS name of your Application Load Balancer follows the format name-1234567890.region.elb.amazonaws.com and is globally resolvable, allowing access from anywhere with internet connectivity.\nVerifying Application Functionality Upon successful connection, you should see the FCJ Management application interface:\nTesting CRUD Operations To verify complete functionality, test the application\u0026rsquo;s data manipulation capabilities:\nSelect a record and click the edit button to modify its information After entering the updated information, click Submit Verify you receive a success notification Return to the homepage to confirm the changes are reflected in the database ‚ö†Ô∏è Warning: If you encounter any errors during testing, verify that your security groups are properly configured to allow traffic on port 5000 and that your target group health checks are passing.\nPerformance Monitoring ‚ÑπÔ∏è Information: In subsequent testing steps, we\u0026rsquo;ll focus on monitoring application metrics through Amazon CloudWatch. While reviewing these metrics, pay attention to any performance degradation that might occur during periods of increased load.\nüîí Security Note: All traffic to your application is now flowing through the Application Load Balancer, which provides an additional security layer by isolating your EC2 instances from direct internet access. Consider implementing AWS WAF with your ALB for additional protection against common web exploits.\n"
},
{
	"uri": "//localhost:1313/6-create-auto-scaling-group/",
	"title": "Create Auto Scaling Group",
	"tags": [],
	"description": "",
	"content": "Overview ‚ÑπÔ∏è Information: Auto Scaling Groups automatically adjust your application\u0026rsquo;s compute capacity based on demand, ensuring optimal performance while controlling costs. In this section, we\u0026rsquo;ll configure an Auto Scaling Group to dynamically manage our EC2 instances behind the Application Load Balancer.\nUnderstanding the Need for Auto Scaling ‚ö†Ô∏è Warning: Our testing revealed performance instability when the application receives high traffic volumes. While manually adding EC2 instances and distributing traffic with a Load Balancer helps, this approach is impractical for several reasons:\nEach new instance requires manual configuration with the application and dependencies Responding to traffic fluctuations requires constant monitoring Manual scaling cannot efficiently respond to unexpected traffic spikes Auto Scaling solves these challenges by automatically adjusting capacity based on defined policies.\nCreating an Auto Scaling Group Navigate to the Auto Scaling Group creation interface:\nIn the EC2 management console: Scroll down the left navigation panel Select Auto Scaling Groups Click Create Auto Scaling group Configuring Launch Template In the Auto Scaling group creation wizard:\nBasic configuration: Name: FCJ-Management-ASG Launch template: select FCJ-Management-template Version: Default (1) ‚ÑπÔ∏è Information: The launch template contains all the configuration details needed to launch instances, including the AMI, instance type, key pair, security groups, and user data scripts.\n‚ö†Ô∏è Warning: The ASG name should match the name specified in section 2.6 for Predictive Scaling configuration. The launch template must include all required components (MySQL Client, Node.js, application source code, and PM2) for proper instance functionality.\nConfiguring Network Settings In the network configuration section:\nVPC: select AutoScaling-Lab Availability Zones and subnets: select all 3 public subnets Click Next üí° Pro Tip: Distributing instances across multiple Availability Zones improves application reliability. If one AZ experiences issues, instances in other AZs continue serving traffic.\nConfiguring Load Balancer Integration Connect your Auto Scaling Group to the previously created load balancer:\nLoad balancing: select Attach to an existing load balancer Attachment method: choose Choose from your load balancer target groups Target group: select FCJ-Management-TG | HTTP ‚ÑπÔ∏è Information: When properly configured, the dropdown will display your existing target group, confirming that both the Application Load Balancer and Target Group are correctly set up.\nFor additional configuration:\nVPC Lattice integration: select No VPC Lattice service Health checks: enable Turn on Elastic Load Balancing health checks Leave remaining health check settings as default Configuring Group Size and Scaling Policies Define the initial capacity and scaling boundaries:\nGroup size: Desired capacity: 1 Scaling limits: Minimum capacity: 1 Maximum capacity: 3 Scaling policies: No scaling policies (we\u0026rsquo;ll configure these in later sections) ‚ÑπÔ∏è Information: We\u0026rsquo;re deferring scaling policy configuration because we\u0026rsquo;ll implement and compare multiple scaling strategies in subsequent sections. For instance maintenance: Select No policy\nUnder Monitoring:\nSelect Enable group metrics collection within CloudWatch Click Next Configuring Notifications Set up Amazon SNS notifications to monitor Auto Scaling events:\nNotification configuration: SNS topic: asg-topic Recipients: enter your email address Event types: select all event types Click Next Review your configuration and click Create Auto Scaling group.\nüîí Security Note: Notifications provide real-time awareness of scaling events, helping you monitor for unexpected behavior that could indicate security issues or application problems.\nVerifying Auto Scaling Group Creation After creation, you\u0026rsquo;ll receive confirmation emails:\nFirst, a subscription confirmation email (requires confirmation) Then, a notification when the first instance launches Verify the Auto Scaling activity in the AWS Management Console:\nSelect your Auto Scaling Group Navigate to the Activity tab to view scaling events ‚ö†Ô∏è Warning: As we implement different scaling strategies in subsequent sections, you may receive numerous notification emails. This is intentional to help you monitor scaling activities.\nüí° Pro Tip: Auto Scaling Groups work best when combined with CloudWatch alarms that trigger scaling actions based on metrics like CPU utilization, network traffic, or custom application metrics. We\u0026rsquo;ll explore these options in upcoming sections.\n"
},
{
	"uri": "//localhost:1313/2-preparation/2.6-prepare-metrics-for-predictive-scaling/",
	"title": "Prepare metric for Predictive scaling",
	"tags": [],
	"description": "",
	"content": "Preparing Data for Predictive Scaling Since Predictive Scaling requires more than 2 days\u0026rsquo; worth of data to make predictions for the following days, and we don‚Äôt have this data available, we will need to simulate such an environment.\nPreparation Steps First, create a new folder named metric-preparation and navigate into this directory.\nmkdir metric-preparation \u0026amp;\u0026amp; cd metric-preparation Then, download the script to prepare the data.\ncurl -o prepare-metric-data.sh https://raw.githubusercontent.com/awslabs/ec2-spot-workshops/master/workshops/efficient-and-resilient-ec2-auto-scaling/prepare-metric-data.sh After downloading, modify the script slightly.\nvim prepare-metric-data.sh Edit the time variable to:\ntime=$(date -d \u0026#34;$((5*i)) minutes ago\u0026#34;) Once the script is edited, proceed to download the raw data, which is why we need to prepare this data processing script first. Start with metrics for the CPU.\ncurl -o metric-cpu.json https://raw.githubusercontent.com/awslabs/ec2-spot-workshops/master/workshops/efficient-and-resilient-ec2-auto-scaling/metric-cpu.json Next, download the data for Instance.\ncurl -o metric-instances.json https://raw.githubusercontent.com/awslabs/ec2-spot-workshops/master/workshops/efficient-and-resilient-ec2-auto-scaling/metric-instances.json Edit the two types of data one by one, starting with CPU.\nbash prepare-metric-data.sh metric-cpu.json FCJ-Management-ASG \u0026amp;\u0026amp; cat metric-cpu.json Then proceed with the instance data.\nbash prepare-metric-data.sh metric-instances.json FCJ-Management-ASG \u0026amp;\u0026amp; cat metric-instances.json The parameter FCJ-Management-ASG that appears in the two commands above is the name of the Auto Scaling Group that we will create later. Therefore, you need to create an ASG with the same name afterward, or you should change it to a different name now.\nUpload Data to CloudWatch In Amazon Linux 2023, if you are using the correct AMI, AWS CLI is pre-installed. At this point, you only need to configure the credentials. Remember that you must have an IAM User with sufficient permissions to upload data to CloudWatch or at least enough to complete this workshop.\nGo to the IAM page, open the IAM User details, and get the Access Key Id and Secret Access Key. If you don\u0026rsquo;t have one, create a new one.\naws configure And configure the credentials.\nAfter that, upload the two data files we prepared earlier to CloudWatch.\naws cloudwatch put-metric-data --namespace \u0026#39;FCJ Management Custom Metrics\u0026#39; --metric-data file://metric-cpu.json aws cloudwatch put-metric-data --namespace \u0026#39;FCJ Management Custom Metrics\u0026#39; --metric-data file://metric-instances.json Verification Finally, we will check the results in CloudWatch.\nSearch for CloudWatch Click to enter the CloudWatch Console. In the CloudWatch Console:\nSelect All metrics Choose FCJ Management Custom Metrics Next, select AutoScalingGroupName.\nThen, select the two parameters as shown in the image, and wait for some time to receive the results.\nWe will have to wait about 30 minutes or longer for CloudWatch to process the data. Instead of waiting, we can proceed with the next sections.\n"
},
{
	"uri": "//localhost:1313/7-test-solutions/",
	"title": "Test solutions",
	"tags": [],
	"description": "",
	"content": "Scaling Solutions \u0026amp; Techniques The Amazon EC2 Auto Scaling service provides different scaling solutions depending on the needs and usage patterns of your workload. To implement the most effective scaling strategy, you\u0026rsquo;ll need to analyze, estimate, observe, and plan the use of each scaling type or combine multiple approaches to increase the flexibility of your system.\nIn this section, we\u0026rsquo;ll explore each solution in detail, but first, let\u0026rsquo;s review the available scaling approaches.\nManual Scaling Manual scaling involves adjusting the desired capacity parameter in your Amazon EC2 Auto Scaling group to scale instances up or down in your target group. This approach is useful for quick, one-off situations where you need to temporarily add or remove capacity.\nScheduled Scaling When you have predictable workload patterns or know when your application will experience high traffic (such as daily, weekly, or annual events), you can configure Amazon EC2 Auto Scaling to automatically adjust capacity according to a defined schedule.\nDynamic Scaling For workloads with unpredictable traffic patterns that are difficult to forecast, you can leverage automatic scaling with Amazon EC2 Auto Scaling. Dynamic scaling policies respond to real-time metrics (such as CPU utilization or request count) to scale your application resources appropriately.\nPredictive Scaling Amazon EC2 Auto Scaling can also analyze historical workload patterns to predict capacity needs for the next 48-72 hours. For systems with variable but somewhat cyclical demands, you can combine predictive scaling with dynamic scaling to optimize resource utilization and responsiveness.\nSince we need historical data for predictive scaling to work effectively, you must complete the steps in 2.6 - Prepare metrics for predictive scaling before proceeding with this section.\nInstalling the Load Testing Tool To simulate high traffic conditions for our tests, we\u0026rsquo;ll use a load testing tool. Download the testing program from: https://www.paessler.com/tools/webstress\nAfter downloading the RAR file, extract and install the application. Once installed, launch the program to see the interface shown below:\nContent Test the manual scaling solution Test the scheduled scaling solution Test the dynamic scaling solution Test the predictive scaling solution This section requires significant time and careful observation. You can analyze results while running the simulations, but be patient and thorough when documenting your findings.\n"
},
{
	"uri": "//localhost:1313/8-cleanup/",
	"title": "Cleanup Resources",
	"tags": [],
	"description": "",
	"content": "Overview ‚ÑπÔ∏è Information: After completing the workshop, it\u0026rsquo;s important to properly clean up all AWS resources to avoid ongoing charges. This section guides you through the systematic removal of all resources created during this workshop.\nDelete Auto Scaling Group Navigate to the EC2 management console In the left navigation pane, scroll down and select Auto Scaling Groups Select the Auto Scaling Group FCJ-Management-ASG Click the Actions button at the top right of the screen Choose Delete Delete Load Balancer In the EC2 management console, on the left navigation pane, select Load Balancers Select the Load Balancer FCJ-Management-LB Click the Actions button Choose Delete load balancer Delete Target Group In the EC2 management console, on the left navigation pane, select Target Groups Select the Target Group FCJ-Management-TG Click the Actions button Choose Delete Delete Launch Template In the EC2 management console, on the left navigation pane, select Launch Templates Select the Launch Template FCJ-Management-TG Click the Actions button Choose Delete template ‚ö†Ô∏è Warning: Ensure you\u0026rsquo;ve terminated all instances using this launch template before deletion to avoid potential errors.\nDeregister AMI In the EC2 management console, on the left navigation pane, select AMIs Select the AMI FCJ-Management-AMI Click the Actions button Choose Deregister AMI üí° Pro Tip: After deregistering an AMI, remember that its associated EBS snapshots will still exist and may incur charges. Consider deleting these snapshots separately if they\u0026rsquo;re no longer needed.\nTerminate EC2 Instance In the EC2 management console, on the left navigation pane, select Instances Select the FCJ-Management instance Click the Instance state button Choose Terminate (delete) instance üîí Security Note: Terminating an instance permanently deletes its instance store volumes. If you have important data, ensure it\u0026rsquo;s backed up before proceeding.\nDelete RDS Database Navigate to the RDS console On the left navigation pane, select Databases Select the database instance fcj-management-db-instance Click Modify In the Modify DB Instance section, scroll down and uncheck Enable deletion protection Click Continue In the Schedule modifications section: Select Apply immediately Click Modify DB instance After the modification completes: Select the database instance fcj-management-db-instance Click the Actions button Choose Delete In the confirmation dialog: Select I acknowledge that upon instance deletion, automated backups, including system snapshots and point-in-time recovery, will no longer be available Enter delete me in the confirmation field Click Delete ‚ö†Ô∏è Warning: This action permanently deletes your database and all its data. If you need to preserve any information, create a final snapshot before deletion.\nDelete Subnet Group In the RDS console, select Subnet groups from the left navigation pane Select the subnet group fcj-management-subnet-group Click Delete ‚ÑπÔ∏è Information: After completing these steps, verify in the AWS Billing Dashboard that there are no unexpected charges related to resources from this workshop. Some resources like EBS snapshots or CloudWatch logs may persist unless explicitly deleted.\n"
},
{
	"uri": "//localhost:1313/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "//localhost:1313/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]